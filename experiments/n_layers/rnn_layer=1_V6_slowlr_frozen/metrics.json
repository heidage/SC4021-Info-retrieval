{
    "train_loss": [
        0.17988352425810364,
        0.17967997832844654,
        0.17927219615214401,
        0.1789337628417545,
        0.17862219115098318,
        0.17832911356041828,
        0.17800939259015852,
        0.1777111750303043,
        0.17724535003718403,
        0.1769009917560551
    ],
    "train_metrics": {
        "accuracy": [
            0.0,
            0.002008032128514056,
            0.002008032128514056,
            0.002008032128514056,
            0.002008032128514056,
            0.002008032128514056,
            0.002008032128514056,
            0.002008032128514056,
            0.006024096385542169,
            0.018072289156626505
        ],
        "f1": [
            0,
            0.6666666666666666,
            0.5,
            0.5,
            0.5,
            0.4,
            0.4,
            0.2857142857142857,
            0.3076923076923077,
            0.47619047619047616
        ],
        "precision": [
            0,
            0.5,
            0.3333333333333333,
            0.3333333333333333,
            0.3333333333333333,
            0.25,
            0.25,
            0.16666666666666666,
            0.18181818181818182,
            0.3125
        ],
        "recall": [
            0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0
        ]
    },
    "val_loss": [
        0.1702648917069802,
        0.16993290759049928,
        0.16960536172756782,
        0.1692790389060974,
        0.16894773107308608,
        0.16861832829622123,
        0.16829131658260638,
        0.1679634669652352,
        0.16763843710605913,
        0.16730250647434822
    ],
    "val_metrics": {
        "accuracy": [
            0.004807692307692308,
            0.004807692307692308,
            0.007211538461538462,
            0.009615384615384616,
            0.01201923076923077,
            0.01201923076923077,
            0.016826923076923076,
            0.026442307692307692,
            0.03365384615384615,
            0.040865384615384616
        ],
        "f1": [
            1.0,
            0.8,
            0.8571428571428571,
            0.888888888888889,
            0.7142857142857143,
            0.6666666666666666,
            0.7368421052631579,
            0.6875000000000001,
            0.6829268292682926,
            0.6938775510204082
        ],
        "precision": [
            1.0,
            0.6666666666666666,
            0.75,
            0.8,
            0.5555555555555556,
            0.5,
            0.5833333333333334,
            0.5238095238095238,
            0.5185185185185185,
            0.53125
        ],
        "recall": [
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0
        ]
    },
    "test_loss": [],
    "test_metrics": {
        "accuracy": [],
        "f1": [],
        "precision": [],
        "recall": []
    },
    "steps": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9
    ],
    "val_steps": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9
    ],
    "grad_norms": [
        6.1638121753931046,
        7.012637749314308,
        5.976871505379677,
        5.714527130126953,
        6.947085753083229,
        6.015371635556221,
        6.10662379860878,
        6.80180324614048,
        7.117214873433113,
        6.439397513866425,
        6.146276906132698,
        6.322613075375557,
        6.2314454317092896,
        6.771799653768539,
        6.43326199054718,
        6.793645158410072,
        5.853950172662735,
        6.21564456820488,
        6.4149947464466095,
        7.364332944154739,
        6.229288935661316,
        6.18829619884491,
        6.829787030816078,
        6.945962131023407,
        5.622181594371796,
        6.842649698257446,
        6.560029223561287,
        6.2777195274829865,
        6.050088256597519,
        5.402254402637482,
        7.178241416811943,
        7.050286263227463,
        6.833995774388313,
        6.3637542724609375,
        6.815078422427177,
        6.8318792283535,
        6.542962417006493,
        5.83086983859539,
        5.76553413271904,
        5.545022577047348,
        6.884485363960266,
        5.724655345082283,
        6.272536754608154,
        7.173298999667168,
        7.059370577335358,
        6.151554003357887,
        6.831845045089722,
        6.371168866753578,
        6.450448930263519,
        5.550241634249687,
        6.847861409187317,
        6.235473468899727,
        7.566272288560867,
        6.638484477996826,
        4.69414184987545,
        7.320331543684006,
        6.79231958091259,
        6.202720478177071,
        6.58189831674099,
        6.236438125371933,
        6.948203429579735,
        6.769581168889999,
        5.791809216141701,
        6.067895010113716,
        6.9235343635082245,
        6.485456362366676,
        5.566062182188034,
        5.902232140302658,
        7.601811900734901,
        6.523544907569885,
        6.448309317231178,
        6.800635278224945,
        5.013146564364433,
        6.104536727070808,
        6.262873336672783,
        6.833598896861076,
        6.174260631203651,
        8.033844888210297,
        6.163415610790253,
        6.494190543889999,
        7.0321377366781235,
        6.700481563806534,
        6.626098915934563,
        5.7005445510149,
        6.866588786244392,
        7.000480934977531,
        6.044831290841103,
        7.236369282007217,
        7.007844999432564,
        6.469599217176437,
        6.205131337046623,
        4.795185387134552,
        6.682560682296753,
        6.112295031547546,
        5.581525519490242,
        6.706070125102997,
        6.263121277093887,
        6.624675288796425,
        5.291146814823151,
        6.313079923391342,
        6.023861259222031,
        7.57519143819809,
        6.451134294271469,
        6.283478036522865,
        7.189340069890022,
        7.469623759388924,
        5.608003541827202,
        5.421510457992554,
        7.481735378503799,
        6.161655783653259,
        6.971409931778908,
        5.738117873668671,
        6.532903000712395,
        7.32761162519455,
        7.341362372040749,
        6.2166291028261185,
        6.850965157151222,
        6.674930587410927,
        6.347475081682205,
        6.568140029907227,
        5.916279345750809,
        6.96459724009037,
        5.9710342437028885,
        5.584534302353859,
        5.443348214030266,
        7.552614837884903,
        5.697701469063759,
        6.233315721154213,
        6.736995726823807,
        5.6728775203228,
        6.018423512578011,
        6.216109976172447,
        7.223542243242264,
        4.987705886363983,
        6.736866787075996,
        6.27423520386219,
        6.537065535783768,
        6.156917929649353,
        7.5343117117881775,
        6.984425917267799,
        5.822979524731636,
        5.8434726148843765,
        8.008268252015114,
        6.813175439834595,
        7.936116948723793,
        6.144693046808243,
        6.757024496793747,
        5.955824613571167,
        5.997946307063103,
        6.20836079120636,
        6.635117918252945,
        6.412179857492447,
        6.452555745840073,
        6.389431178569794,
        6.516635954380035,
        6.750846445560455,
        5.067243799567223,
        5.761186495423317,
        6.899095326662064,
        7.726088032126427
    ],
    "grad_steps": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160
    ]
}