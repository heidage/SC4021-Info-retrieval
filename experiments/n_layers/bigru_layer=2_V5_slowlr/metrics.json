{
    "train_loss": [
        0.022658581943496278,
        0.022522013658951772,
        0.022398394936891764,
        0.022272315599318398,
        0.022170215122107612,
        0.022036897036933192,
        0.021981726553732234,
        0.02181192434172293,
        0.021737366712554114,
        0.02166196214966476
    ],
    "train_metrics": {
        "accuracy": [
            0.4308617234468938,
            0.5891783567134269,
            0.6312625250501002,
            0.6653306613226453,
            0.6693386773547094,
            0.6693386773547094,
            0.6753507014028056,
            0.6813627254509018,
            0.687374749498998,
            0.6933867735470942
        ],
        "f1": [
            0.34862385321100914,
            0.3322475570032573,
            0.25203252032520324,
            0.2085308056872038,
            0.17910447761194032,
            0.16243654822335027,
            0.1473684210526316,
            0.1497326203208556,
            0.15217391304347824,
            0.15469613259668508
        ],
        "precision": [
            0.24918032786885247,
            0.2897727272727273,
            0.26956521739130435,
            0.275,
            0.2571428571428571,
            0.24242424242424243,
            0.23728813559322035,
            0.25,
            0.2641509433962264,
            0.28
        ],
        "recall": [
            0.5801526717557252,
            0.3893129770992366,
            0.2366412213740458,
            0.16793893129770993,
            0.13740458015267176,
            0.12213740458015267,
            0.10687022900763359,
            0.10687022900763359,
            0.10687022900763359,
            0.10687022900763359
        ]
    },
    "val_loss": [
        0.023460820530696463,
        0.02326474306432323,
        0.02309528537120463,
        0.022881071917557467,
        0.022720110343976155,
        0.022577310634207808,
        0.02240075244076757,
        0.022145585221652355,
        0.0220380344415187,
        0.02185781033606165
    ],
    "val_metrics": {
        "accuracy": [
            0.4875124875124875,
            0.6553446553446554,
            0.7202797202797203,
            0.7412587412587412,
            0.7582417582417582,
            0.7652347652347652,
            0.7682317682317682,
            0.7712287712287712,
            0.7762237762237763,
            0.7762237762237763
        ],
        "f1": [
            0.25544267053701014,
            0.20323325635103925,
            0.1411042944785276,
            0.12794612794612795,
            0.12318840579710146,
            0.10646387832699618,
            0.072,
            0.05761316872427982,
            0.05084745762711864,
            0.05084745762711864
        ],
        "precision": [
            0.17635270541082165,
            0.18106995884773663,
            0.16911764705882354,
            0.17757009345794392,
            0.19767441860465115,
            0.1917808219178082,
            0.15,
            0.1320754716981132,
            0.13043478260869565,
            0.13043478260869565
        ],
        "recall": [
            0.4631578947368421,
            0.23157894736842105,
            0.12105263157894737,
            0.1,
            0.08947368421052632,
            0.07368421052631578,
            0.04736842105263158,
            0.03684210526315789,
            0.031578947368421054,
            0.031578947368421054
        ]
    },
    "test_loss": [],
    "test_metrics": {
        "accuracy": [],
        "f1": [],
        "precision": [],
        "recall": []
    },
    "steps": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9
    ],
    "val_steps": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9
    ],
    "grad_norms": [
        3.8392144357785583,
        2.493837038287893,
        1.961761190526886,
        2.000100452147308,
        2.1147018934425432,
        3.1488189620431513,
        2.6872729402093682,
        1.8837849519914016,
        3.331495378515683,
        2.8238683058298193,
        4.240203214867506,
        1.33995808083273,
        2.4699675423034932,
        2.6809682053572033,
        1.8856297715537949,
        1.2573974176775664,
        1.70204913103953,
        2.294519605085952,
        3.1173564139171503,
        2.6739652705582557,
        1.450499002909055,
        2.0707586124772206,
        3.3226594587031286,
        3.746444487682311,
        2.9736666643584613,
        2.1722462420875672,
        3.352237041166518,
        1.252514390173019,
        2.1880096147942822,
        3.4894938214565627,
        1.4123659761826275,
        2.8829277808545157,
        2.005156278173672,
        2.4884336754330434,
        1.7455186042061541,
        2.435583783968468,
        3.3590143610781524,
        1.0282969262771076,
        2.5855729087488726,
        3.355433014774462,
        1.7800806136365281,
        3.364901830558665,
        1.8210974284593249,
        3.1827179186802823,
        3.577790247829398,
        2.512324380717473,
        1.9338606521196198,
        2.107714505473268,
        2.3074405847874004,
        2.823738031787798,
        3.3751664670126047,
        0.79413956523058,
        2.9012067685252987,
        2.944702257984318,
        1.9566339051089017,
        2.457351754885167,
        1.6435344553756295,
        2.224079713196261,
        1.4646581699053058,
        3.183186070964439,
        2.7719816227909178,
        3.3482838818163145,
        2.2604164874064736,
        2.387011103652185,
        4.020913258078508,
        3.8513782283989713,
        2.1483580586209428,
        3.161764817428775,
        3.1539702661393676,
        2.157773285609437,
        2.2821920896531083,
        2.6495836040121503,
        1.8563970137620345,
        1.3126913170999615,
        2.730270220024977,
        1.588907343611936,
        2.275253632920794,
        1.4305548087577336,
        1.4441746395023074,
        1.6092382722563343,
        3.2760335521015804,
        1.6446528011001647,
        2.193765766947763,
        2.970638405357022,
        1.9218274645681959,
        1.7302635621017544,
        1.3713297725480516,
        2.1512501807446824,
        2.0728482358390465,
        2.054391050245613,
        3.7454613783047535,
        1.8651584594044834,
        2.2867691749706864,
        2.162735372839961,
        3.394908429851057,
        2.1386220205167774,
        2.7412351842503995,
        3.3957112613716163,
        2.42339873520541,
        2.2026525333349127,
        1.9663826932956,
        1.868175469659036,
        2.196600560040679,
        2.0397819159115897,
        1.9362625249486882,
        2.4125643446750473,
        1.2611645916622365,
        2.965469827671768,
        3.1232604382676072,
        2.251441880565835,
        2.901094958651811,
        0.46910423144800006,
        3.5227056506846566,
        2.109556743671419,
        2.6178335114382207,
        2.02320231217891,
        1.5257333056651987,
        1.5340934526902856,
        1.4196344072406646,
        2.9139941096073017,
        2.3851833461085334,
        1.0017556856473675,
        0.5657026958124334,
        2.462534974445589,
        3.701996836287435,
        3.165457065042574,
        2.178345144406194,
        3.026195340513368,
        2.0322711437620455,
        1.6966916490055155,
        3.036575872072717,
        1.7690464331535622,
        1.550406577262038,
        2.868626312818378,
        2.418427507596789,
        3.1632014356728178,
        2.850344520295039,
        1.6310421225789469,
        1.52858661103528,
        3.539167807844933,
        2.0592336097324733,
        2.0202560454781633,
        0.975356751907384,
        2.027684875021805,
        2.1250439808063675,
        2.5213413555466104,
        2.1836667315801606,
        2.140725188277429,
        3.096235455654096,
        2.585075412032893,
        2.299516956525622,
        3.444013355561765,
        2.774681701150257,
        0.6756367414345732,
        2.6928353401017375,
        1.785728908071178,
        1.0868593412014889,
        1.6460358910262585,
        2.08356220384303,
        1.1006534687476233
    ],
    "grad_steps": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160
    ]
}