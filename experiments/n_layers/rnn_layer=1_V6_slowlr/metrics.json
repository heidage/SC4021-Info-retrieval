{
    "train_loss": [
        0.023459001625370648,
        0.02330578241445538,
        0.02316214970778674,
        0.023013087067132194,
        0.022911708607959252,
        0.022772868293234043,
        0.022668881923891604,
        0.02254241752800428,
        0.022449233362244234,
        0.022317013535131183
    ],
    "train_metrics": {
        "accuracy": [
            0.2791164658634538,
            0.285140562248996,
            0.29116465863453816,
            0.2991967871485944,
            0.3232931726907631,
            0.42369477911646586,
            0.5321285140562249,
            0.6526104417670683,
            0.6566265060240963,
            0.6566265060240963
        ],
        "f1": [
            0.41243862520458263,
            0.41059602649006627,
            0.4106844741235392,
            0.4013722126929674,
            0.39279279279279283,
            0.40824742268041236,
            0.391644908616188,
            0.38869257950530034,
            0.3643122676579926,
            0.35471698113207545
        ],
        "precision": [
            0.2625,
            0.26215644820295986,
            0.26282051282051283,
            0.2588495575221239,
            0.25707547169811323,
            0.2796610169491525,
            0.2976190476190476,
            0.3618421052631579,
            0.35507246376811596,
            0.35074626865671643
        ],
        "recall": [
            0.9618320610687023,
            0.9465648854961832,
            0.9389312977099237,
            0.8931297709923665,
            0.8320610687022901,
            0.7557251908396947,
            0.5725190839694656,
            0.4198473282442748,
            0.37404580152671757,
            0.35877862595419846
        ]
    },
    "val_loss": [
        0.02183997530776721,
        0.02180622503734552,
        0.021776030556513712,
        0.02174917909388359,
        0.021725941449403763,
        0.021703453734517097,
        0.02168518677353859,
        0.02167014663036053,
        0.0216563491580578,
        0.021646970739731423
    ],
    "val_metrics": {
        "accuracy": [
            0.4567307692307692,
            0.4543269230769231,
            0.4543269230769231,
            0.46153846153846156,
            0.4735576923076923,
            0.49278846153846156,
            0.5096153846153846,
            0.5216346153846154,
            0.5216346153846154,
            0.5240384615384616
        ],
        "f1": [
            0.6208053691275168,
            0.6146010186757215,
            0.6106346483704975,
            0.6028368794326242,
            0.5730994152046783,
            0.4964200477326969,
            0.2608695652173913,
            0.20080321285140562,
            0.20080321285140562,
            0.20161290322580644
        ],
        "precision": [
            0.45566502463054187,
            0.45363408521303256,
            0.4529262086513995,
            0.45454545454545453,
            0.4551083591331269,
            0.45414847161572053,
            0.4186046511627907,
            0.423728813559322,
            0.423728813559322,
            0.43103448275862066
        ],
        "recall": [
            0.9736842105263158,
            0.9526315789473684,
            0.9368421052631579,
            0.8947368421052632,
            0.7736842105263158,
            0.5473684210526316,
            0.18947368421052632,
            0.13157894736842105,
            0.13157894736842105,
            0.13157894736842105
        ]
    },
    "test_loss": [],
    "test_metrics": {
        "accuracy": [],
        "f1": [],
        "precision": [],
        "recall": []
    },
    "steps": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9
    ],
    "val_steps": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9
    ],
    "grad_norms": [
        2.9992329694505315,
        1.2237190170562826,
        2.1621874891861808,
        4.497372009209357,
        3.838578463968588,
        3.757147044118028,
        2.0326887101109605,
        3.6009115300839767,
        1.5906145958288107,
        1.8134505675116088,
        3.942027849290753,
        1.8951080293481937,
        1.5132803057204,
        2.25132712625782,
        2.571818934578914,
        5.032937508774921,
        2.805019002960762,
        2.6315835996356327,
        3.1738472392316908,
        2.669020481975167,
        2.5977531474491116,
        3.954528418544214,
        2.658395775797544,
        2.137673196484684,
        2.726351492892718,
        2.9179587719554547,
        3.5760052803962026,
        1.9170789181807777,
        2.1451443282712717,
        2.344760715495795,
        2.144986192084616,
        2.6993762149941176,
        2.2889260058291256,
        2.4962684876518324,
        3.3059693983232137,
        3.8582856006978545,
        4.053903641848592,
        2.569488486216869,
        5.030495964165311,
        2.9872810593806207,
        1.3225283261126606,
        1.9284002210188191,
        0.4549960628064582,
        1.9685130783473141,
        2.220040906686336,
        3.6505567626445554,
        1.6574999570439104,
        2.9600994118954986,
        2.6127209125552326,
        4.093484935787274,
        2.222086863068398,
        3.338814994232962,
        2.3240591928188223,
        2.209578198962845,
        2.441735944885295,
        3.102135179389734,
        1.553751145635033,
        2.408947170013562,
        3.0032678583520465,
        2.299258619590546,
        3.1770580227603205,
        2.4290629984461702,
        1.8656895850144792,
        2.3186101124010747,
        2.3828990370675456,
        1.9399901955912355,
        2.0671803045261186,
        3.258526555582648,
        2.345977175689768,
        2.3234616526169702,
        2.641994993959088,
        1.7242445916199358,
        1.8598723909817636,
        2.815999213256873,
        3.413817325315904,
        2.362349166040076,
        3.4429517552780453,
        1.523124713508878,
        2.924660588352708,
        4.723469924036181,
        3.386654489353532,
        3.800100337830372,
        0.9550904774587252,
        4.023062337742886,
        1.5652653155702865,
        1.9725843867490767,
        1.941765310446499,
        2.561178620904684,
        2.459432618372375,
        2.554448011389468,
        3.2097609620832372,
        2.009906391343975,
        0.7431228678178741,
        2.9018620487477165,
        3.6347276310261805,
        2.542573450715281,
        2.308958218054613,
        1.7854862179519841,
        4.152767179883085,
        2.1989366629277356,
        1.7077730055025313,
        2.4418222059030086,
        3.8705242819851264,
        1.9075987957330653,
        1.606997805152787,
        3.680048438720405,
        2.4022689051635098,
        2.534608909540111,
        1.8077037148614181,
        1.479743667441653,
        3.3658507640648168,
        2.2608334112592274,
        2.980023581214482,
        1.2384855128038907,
        3.4049520517291967,
        1.7027348886185791,
        2.2101988868962508,
        3.6052791640977375,
        0.7941167840617709,
        2.7843349608010612,
        3.313517156551825,
        2.859731822143658,
        1.9768556333438028,
        0.5336183942854404,
        3.761106231948361,
        2.72342017426854,
        2.793161013512872,
        2.492293922812678,
        3.24909664853476,
        2.8285655390645843,
        3.4600354882713873,
        3.035530968947569,
        1.8924536209960934,
        2.52759116247762,
        1.8428877068363363,
        1.739229965445702,
        2.558187978924252,
        2.823991457291413,
        2.44109486285015,
        1.752130500273779,
        1.8897469541843748,
        3.149452364858007,
        1.8121221159526613,
        0.7003315480542369,
        3.3955214379529934,
        1.727782697911607,
        3.4066886603832245,
        2.7260604496404994,
        0.7180480454699136,
        2.402806460711872,
        1.6326528298814083,
        1.9437565155531047,
        1.1777710934838979,
        1.796075638718321,
        3.6376702972629573,
        3.2290629482013173,
        1.8348948608909268,
        2.686605162831256,
        2.8763715729874093,
        2.4742142816248816
    ],
    "grad_steps": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160
    ]
}