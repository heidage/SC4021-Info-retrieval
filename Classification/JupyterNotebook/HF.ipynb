{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f8da88-ef68-4226-a519-e2df983c344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24517bc3-4f2c-4131-b5cc-2e55632da6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4353fa0c-5283-4f87-a2d0-26491fd30363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1f4120c-3c50-411d-83dc-8d3a3a0ae2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7377dbfc-1e20-414a-b3ff-f6f82cde0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "# Function to clean text: Tokenization, Lemmatization, and Stopword removal\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):  # Check if the text is a string\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        tokens = word_tokenize(text)  # Tokenize the text\n",
    "\n",
    "        # Lemmatize each token\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "        # Additional preprocessing (like removing stopwords)\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens_without_stopwords = [token for token in lemmatized_tokens if token not in stop_words]\n",
    "\n",
    "        # Rejoin tokens into a single string before passing to TextBlob\n",
    "        cleaned_text = \" \".join(tokens_without_stopwords)\n",
    "        return cleaned_text\n",
    "    else:\n",
    "        # If the text is not a string (e.g., NaN or float), return an empty string or a default value\n",
    "        return \"\"  # Or return a string like 'Invalid Text' if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb7416ae-0f0d-4b45-bffb-f7f3c77f30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def extract_entities(text):\n",
    "    # Step 1: Use spaCy to extract entities (like companies, products, etc.)\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text for ent in doc.ents if ent.label_ == \"ORG\"]  # Extracting organizations\n",
    "\n",
    "    # Step 2: Apply POS tagging to the tokens in the text\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    pos_tags = pos_tag(tokens)  # Get POS tags for the tokens\n",
    "\n",
    "    # Step 3: Extract proper nouns (NNP) or important nouns (NN) using POS tagging\n",
    "    nouns = [word for word, tag in pos_tags if tag in [\"NNP\",\"NN\"]]  # Extracting proper nouns and common nouns\n",
    "\n",
    "    # Combine NER and POS results\n",
    "    refined_entities = list(set(entities + nouns))  # Combine and remove duplicates\n",
    "    return refined_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a55edd0-42f8-49c0-a87c-06da48902375",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Function to load data from Excel\n",
    "def load_data_from_excel(file_path):\n",
    "    # Read the Excel file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Assuming the Excel file has columns 'text' for the comments\n",
    "    texts = df['cleaned_body'].tolist()  # List of texts (Reddit posts)\n",
    "    return df, texts\n",
    "\n",
    "def load_val_data_from_excel(file_path):\n",
    "    # Read the Excel file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Assuming the Excel file has columns 'text' for the comments\n",
    "    texts = df['comment_body'].tolist()  # List of texts (Reddit posts)\n",
    "    return df, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91bb5860-3a37-411a-a439-5e81e8417df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform sentiment analysis with TextBlob\n",
    "def analyze_sentiment_with_textblob(texts):\n",
    "    subjectivity = []\n",
    "    polarity = []\n",
    "    for text in texts:\n",
    "        blob = TextBlob(text)\n",
    "        subjectivity.append(blob.sentiment.subjectivity)\n",
    "        polarity.append(blob.sentiment.polarity)\n",
    "    return subjectivity, polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd81035e-9688-4f7f-b838-0cfd54489cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Time: 1.8210 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load data from Excel sheet\n",
    "train_file_path = \"SC4021 Data Records_train_dataset.csv\"  # Replace with your actual Excel file path\n",
    "val_file_path = \"SC4021 Data Records_evaluation_dataset.csv\"  # Replace with your actual Excel file path\n",
    "df_train, train_texts = load_data_from_excel(train_file_path)\n",
    "df_val, val_texts = load_val_data_from_excel(val_file_path)\n",
    "\n",
    "# --- 1. Preprocess the text ---\n",
    "start_time = time.time()\n",
    "train_cleaned_texts = [clean_text(text) for text in train_texts]\n",
    "val_cleaned_texts = [clean_text(text) for text in val_texts]\n",
    "\n",
    "preprocessing_time = time.time() - start_time\n",
    "print(f\"Preprocessing Time: {preprocessing_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37830680-052e-41ad-a8db-77285202f7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Time: 0.2916 seconds\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Sentiment Analysis with TextBlob ---\n",
    "start_time = time.time()\n",
    "train_subjectivity, train_polarity = analyze_sentiment_with_textblob(train_cleaned_texts)\n",
    "val_subjectivity, val_polarity = analyze_sentiment_with_textblob(val_cleaned_texts)\n",
    "sentiment_analysis_time = time.time() - start_time\n",
    "print(f\"Sentiment Analysis Time: {sentiment_analysis_time:.4f} seconds\")\n",
    "\n",
    "# Append the sentiment analysis results to the dataframe\n",
    "df_train['subjectivity'] = train_subjectivity\n",
    "df_train['polarity'] = train_polarity\n",
    "\n",
    "df_val['subjectivity'] = val_subjectivity\n",
    "df_val['polarity'] = val_polarity\n",
    "# --- 3. Entity Extraction ---\n",
    "\n",
    "# Determine the overall sentiment (positive, negative, neutral)\n",
    "train_sentiment_labels = []\n",
    "for polarity_score in train_polarity:\n",
    "    if polarity_score > 0:\n",
    "        train_sentiment_labels.append('positive')\n",
    "    elif polarity_score < 0:\n",
    "        train_sentiment_labels.append('negative')\n",
    "    else:\n",
    "        train_sentiment_labels.append('neutral')\n",
    "\n",
    "val_sentiment_labels = []\n",
    "for polarity_score in val_polarity:\n",
    "    if polarity_score > 0:\n",
    "        val_sentiment_labels.append('positive')\n",
    "    elif polarity_score < 0:\n",
    "        val_sentiment_labels.append('negative')\n",
    "    else:\n",
    "        val_sentiment_labels.append('neutral')\n",
    "\n",
    "df_val['sentiment'] = val_sentiment_labels\n",
    "df_train['sentiment'] = train_sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5cb8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0d99a3d-e310-43df-98a9-857afb21e144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['type', 'datetime', 'post_id', 'subreddit', 'title', 'author', 'url',\n",
      "       'upvotes', 'downvotes', 'upvote_ratio', 'body', 'cleaned_body', 'Label',\n",
      "       'subjectivity', 'polarity', 'sentiment'],\n",
      "      dtype='object')\n",
      "Index(['title', 'post_id', 'post_url', 'post_content', 'post_content.1',\n",
      "       'subreddit', 'comment_body', 'label', 'comment_author', 'comment_score',\n",
      "       'created', 'created_iso', 'readable_date', 'subjectivity', 'polarity',\n",
      "       'sentiment'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(499, 1001)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 3. Remove neutral sentiment rows ---\n",
    "# df_train_filtered = df_train[df_train['sentiment'] != 'neutral']  # Drop all rows where sentiment is 'neutral'\n",
    "# df_val_filtered = df_val[df_val['sentiment'] != 'neutral']  # Drop all rows where sentiment is 'neutral'\n",
    "# len(df_train_filtered), len(df_val_filtered)\n",
    "print(df_train.columns)\n",
    "print(df_val.columns)\n",
    "df_train_filtered = df_train[df_train['Label'] != 0.0]  # Drop all rows where sentiment is 'neutral'\n",
    "df_val_filtered = df_val[df_val['label'] != 0.0]  # Drop all rows where sentiment is 'neutral'\n",
    "len(df_train_filtered), len(df_val_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a27231a-4982-4124-b5a7-1860ed6d60ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Extraction Time: 16.1714 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_357607/3855849855.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_filtered['entities'] = train_entities\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Named Entity Recognition ---\n",
    "start_time = time.time()\n",
    "# Apply NER only to the remaining (non-neutral) rows\n",
    "train_remaining_texts = df_train_filtered['cleaned_body'].tolist()  # Only the rows with non-neutral sentiment\n",
    "val_remaining_texts = df_val_filtered['comment_body'].tolist()  # Only the rows with non-neutral sentiment\n",
    "train_entities = [extract_entities(text) for text in train_remaining_texts]\n",
    "val_entities = [extract_entities(text) for text in val_remaining_texts]\n",
    "\n",
    "entity_extraction_time = time.time() - start_time\n",
    "print(f\"Entity Extraction Time: {entity_extraction_time:.4f} seconds\")\n",
    "\n",
    "# Append extracted entities to the dataframe\n",
    "df_train_filtered['entities'] = train_entities\n",
    "df_val_filtered['entities'] = val_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2225c763-97ff-4fcb-96bb-c4c848023266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified data saved to SentimentedTrain.csv\n",
      "Modified data saved to SentimentedVal.csv\n",
      "\n",
      "--- Performance Metrics ---\n",
      "Total Time for Preprocessing, Sentiment Analysis, and Entity Extraction: 18.2840 seconds\n",
      "Records Classified per Second: 82.04 records/second\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Save the modified data back to CSV ---\n",
    "output_file_path = \"SentimentedTrain.csv\"\n",
    "to_df_train_filtered = df_train_filtered.rename(columns={'cleaned_body': 'text', 'Label': 'label'})\n",
    "to_df_train_filtered = to_df_train_filtered[['text', 'label']]\n",
    "to_df_train_filtered.to_csv(output_file_path, index=False)\n",
    "print(f\"Modified data saved to {output_file_path}\")\n",
    "\n",
    "output_file_path = \"SentimentedVal.csv\"\n",
    "to_df_val_filtered = df_val_filtered.rename(columns={'comment_body': 'text', 'Label': 'label'})\n",
    "to_df_val_filtered = to_df_val_filtered[['text', 'label']]\n",
    "to_df_val_filtered.to_csv(output_file_path, index=False)\n",
    "print(f\"Modified data saved to {output_file_path}\")\n",
    "\n",
    "# --- Performance Metrics ---\n",
    "total_time = preprocessing_time + sentiment_analysis_time + entity_extraction_time\n",
    "records_per_second = (len(df_train_filtered) + len(df_val_filtered)) / total_time  # records classified per second\n",
    "\n",
    "print(f\"\\n--- Performance Metrics ---\")\n",
    "print(f\"Total Time for Preprocessing, Sentiment Analysis, and Entity Extraction: {total_time:.4f} seconds\")\n",
    "print(f\"Records Classified per Second: {records_per_second:.2f} records/second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60cf83d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot perform 'rand_' with a dtyped [float64] array and scalar of type [bool]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/2dgs/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:362\u001b[39m, in \u001b[36mna_logical_op\u001b[39m\u001b[34m(x, y, op)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    354\u001b[39m     \u001b[38;5;66;03m# For exposition, write:\u001b[39;00m\n\u001b[32m    355\u001b[39m     \u001b[38;5;66;03m#  yarr = isinstance(y, np.ndarray)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    360\u001b[39m     \u001b[38;5;66;03m# Then Cases where this goes through without raising include:\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;66;03m#  (xint or xbool) and (yint or bool)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m     result = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/2dgs/lib/python3.12/site-packages/pandas/core/roperator.py:54\u001b[39m, in \u001b[36mrand_\u001b[39m\u001b[34m(left, right)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrand_\u001b[39m(left, right):\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mand_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/2dgs/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:376\u001b[39m, in \u001b[36mna_logical_op\u001b[39m\u001b[34m(x, y, op)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     result = \u001b[43mlibops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscalar_binop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[32m    378\u001b[39m     \u001b[38;5;167;01mTypeError\u001b[39;00m,\n\u001b[32m    379\u001b[39m     \u001b[38;5;167;01mValueError\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     \u001b[38;5;167;01mNotImplementedError\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mops.pyx:180\u001b[39m, in \u001b[36mpandas._libs.ops.scalar_binop\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Buffer dtype mismatch, expected 'Python object' but got 'double'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m to_df_train_filtered = to_df_train_filtered[[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m      6\u001b[39m original_train_size = \u001b[38;5;28mlen\u001b[39m(df_train_filtered)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df_msk = (to_df_train_filtered[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m] == \u001b[32;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m&\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_df_train_filtered\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m == -\u001b[32m1.0\u001b[39m)\n\u001b[32m      8\u001b[39m to_df_train_filtered = to_df_train_filtered[df_msk]\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(Counter(to_df_train_filtered[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/2dgs/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/2dgs/lib/python3.12/site-packages/pandas/core/arraylike.py:74\u001b[39m, in \u001b[36mOpsMixin.__rand__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__rand__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__rand__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_logical_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/2dgs/lib/python3.12/site-packages/pandas/core/series.py:6130\u001b[39m, in \u001b[36mSeries._logical_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6127\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6128\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6130\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogical_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/2dgs/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:454\u001b[39m, in \u001b[36mlogical_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    451\u001b[39m     \u001b[38;5;66;03m# i.e. scalar\u001b[39;00m\n\u001b[32m    452\u001b[39m     is_other_int_dtype = lib.is_integer(rvalues)\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m res_values = \u001b[43mna_logical_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# For int vs int `^`, `|`, `&` are bitwise operators and return\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m#   integer dtypes.  Otherwise these are boolean ops\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (left.dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_other_int_dtype):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/2dgs/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:385\u001b[39m, in \u001b[36mna_logical_op\u001b[39m\u001b[34m(x, y, op)\u001b[39m\n\u001b[32m    377\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[32m    378\u001b[39m             \u001b[38;5;167;01mTypeError\u001b[39;00m,\n\u001b[32m    379\u001b[39m             \u001b[38;5;167;01mValueError\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m             \u001b[38;5;167;01mNotImplementedError\u001b[39;00m,\n\u001b[32m    383\u001b[39m         ) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    384\u001b[39m             typ = \u001b[38;5;28mtype\u001b[39m(y).\u001b[34m__name__\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    386\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot perform \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m with a dtyped [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] array \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    387\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mand scalar of type [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    388\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result.reshape(x.shape)\n",
      "\u001b[31mTypeError\u001b[39m: Cannot perform 'rand_' with a dtyped [float64] array and scalar of type [bool]"
     ]
    }
   ],
   "source": [
    "# --- 5. Save the modified data back to CSV ---\n",
    "from collections import Counter\n",
    "output_file_path = \"train.csv\"\n",
    "to_df_train_filtered = df_train_filtered.rename(columns={'cleaned_body': 'text', 'Label': 'label'})\n",
    "to_df_train_filtered = to_df_train_filtered[['text', 'label']]\n",
    "original_train_size = len(df_train_filtered)\n",
    "df_msk = (to_df_train_filtered['label'] == 1.0) & (to_df_train_filtered['label'] == -1.0)\n",
    "to_df_train_filtered = to_df_train_filtered[df_msk]\n",
    "print(Counter(to_df_train_filtered['label']))\n",
    "def map_labels(label):\n",
    "    if label == 1.0:\n",
    "        return 1\n",
    "    elif label == -1.0:\n",
    "        return 0\n",
    "def map_val_labels(label):\n",
    "    if label == '-1':\n",
    "        return 0\n",
    "    elif label == '1':\n",
    "        return 1\n",
    "to_df_train_filtered['label'] = to_df_train_filtered['label'].apply(lambda x: map_labels(x))\n",
    "print(Counter(to_df_train_filtered['label']))\n",
    "to_df_train_filtered.to_csv(output_file_path, index=False)\n",
    "print(f\"Modified data saved to {output_file_path}. From {original_train_size} to {len(to_df_train_filtered)} records.\")\n",
    "\n",
    "output_file_path = \"val.csv\"\n",
    "to_df_val_filtered = df_val_filtered.rename(columns={'comment_body': 'text', 'Label': 'label'})\n",
    "to_df_val_filtered = to_df_val_filtered[['text', 'label']]\n",
    "original_val_size = len(to_df_val_filtered)\n",
    "df_msk = (to_df_val_filtered['label'] == '1' & to_df_val_filtered['label'] == '-1')\n",
    "to_df_val_filtered = to_df_val_filtered[df_msk]\n",
    "print(Counter(to_df_val_filtered['label']))\n",
    "to_df_val_filtered ['label'] = to_df_val_filtered ['label'].apply(lambda x: map_val_labels(x))\n",
    "print(Counter(to_df_val_filtered['label']))\n",
    "to_df_val_filtered.to_csv(output_file_path, index=False)\n",
    "print(f\"Modified data saved to {output_file_path}. From {original_val_size} to {len(to_df_val_filtered)} records.\")\n",
    "\n",
    "# --- Performance Metrics ---\n",
    "total_time = preprocessing_time + sentiment_analysis_time + entity_extraction_time\n",
    "records_per_second = (len(df_train_filtered) + len(df_val_filtered)) / total_time  # records classified per second\n",
    "\n",
    "print(f\"\\n--- Performance Metrics ---\")\n",
    "print(f\"Total Time for Preprocessing, Sentiment Analysis, and Entity Extraction: {total_time:.4f} seconds\")\n",
    "print(f\"Records Classified per Second: {records_per_second:.2f} records/second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85b0c011-064c-4304-8004-349032bec376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/974ksd917bx0z_pnb3yqq52h0000gn/T/ipykernel_24739/1604689874.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df1['sentiment'] = df1['sentiment'].replace({'positive': 1.0, 'negative': -1.0})\n"
     ]
    }
   ],
   "source": [
    "#Combining the labelled data \n",
    "# Load the datasets\n",
    "df1 = pd.read_csv('/Users/jaredog/Downloads/git code/SC4021-Info-retrieval/ClassificationNew/JupyterNotebook/Sentimented.csv')  # Replace with your dataset file paths\n",
    "df2 = pd.read_csv('/Users/jaredog/Downloads/git code/SC4021-Info-retrieval/ClassificationNew/JupyterNotebook/Labelled.csv')\n",
    "\n",
    "df1['sentiment'] = df1['sentiment'].replace({'positive': 1.0, 'negative': -1.0})\n",
    "# Merge the datasets based on 'post_id' column\n",
    "merged_df = pd.merge(df1, df2[['post_id', ' Label']], on='post_id', how='inner')\n",
    "\n",
    "# If you want to append the 'label' column from df2 to df1\n",
    "df1['label'] = merged_df[' Label']\n",
    "df1 = df1[df1['label'] != 0.0]\n",
    "df1 = df1.dropna(subset=['label'])\n",
    "\n",
    "# Save the resulting dataframe to a new CSV file\n",
    "df1.to_csv('Sentimented+Labelled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ede4112e-bf50-4b09-a034-e559aeee7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df1\n",
    "\n",
    "# Step 1: Vectorize the cleaned text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_text = vectorizer.fit_transform(data['cleaned_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69dde612-43c9-4da2-a55d-b2148740e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Add subjectivity and polarity as features\n",
    "X_features = data[['subjectivity', 'polarity']].values\n",
    "\n",
    "# Combine the text features and sentiment features\n",
    "from scipy.sparse import hstack\n",
    "X_combined = hstack([X_text, X_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c29fd66-5da4-4ce7-ab15-4805d9a5fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Convert 'entities' column into binary features (one-hot encoding)\n",
    "mlb = MultiLabelBinarizer()\n",
    "entity_features = mlb.fit_transform(data['entities'].apply(eval))  # Convert string lists into actual lists\n",
    "\n",
    "# Combine entity features with the other features\n",
    "X_combined_with_entities = hstack([X_combined, entity_features])\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=50)\n",
    "X_combined_with_entities_pca = pca.fit_transform(X_combined_with_entities.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eff619f5-054b-424e-b5fa-59ca787c9d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Apply KMeans clustering\n",
    "start_time = time.time()\n",
    "\n",
    "kmeans_with_entities = KMeans(n_clusters=6, random_state=42)\n",
    "kmeans_with_entities.fit(X_combined_with_entities_pca)\n",
    "\n",
    "# Add cluster labels to the dataframe\n",
    "predicted_labels = kmeans_with_entities.labels_\n",
    "predicted_labels = predicted_labels.astype(int)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "records_classified_per_second = len(data) / total_time  # Assuming 'data' contains all records\n",
    "\n",
    "# Step 6: Map clusters to sentiment labels\n",
    "# Create a mapping based on the majority sentiment in each cluster\n",
    "cluster_sentiment_mapping = {}\n",
    "\n",
    "for cluster in range(kmeans_with_entities.n_clusters):\n",
    "    # Find the rows that belong to this cluster\n",
    "    cluster_rows = data[predicted_labels == cluster]\n",
    "    # Majority sentiment in the cluster\n",
    "    majority_sentiment = cluster_rows['label'].mode()[0]\n",
    "    # Map this cluster to the majority sentiment\n",
    "    cluster_sentiment_mapping[cluster] = majority_sentiment\n",
    "\n",
    "# Map predicted labels to sentiment labels\n",
    "mapped_sentiment_labels = [cluster_sentiment_mapping[label] for label in predicted_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9ec65b6-441f-4f45-b584-0de4f128d204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8037\n",
      "Recall: 0.7313\n",
      "F1-Score: 0.6206\n",
      "Accuracy: 0.7313\n",
      "Records Classified per Second: 12287.63\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Get the true labels for the remaining rows\n",
    "true_labels = data['label']\n",
    "\n",
    "# Step 8: Evaluate clustering performance using Precision, Recall, F1-Score\n",
    "precision = precision_score(true_labels, mapped_sentiment_labels, average='weighted', zero_division=1)  # Handling zero divisions\n",
    "recall = recall_score(true_labels, mapped_sentiment_labels, average='weighted', zero_division=1)\n",
    "f1 = f1_score(true_labels, mapped_sentiment_labels, average='weighted', zero_division=1)\n",
    "accuracy = accuracy_score(true_labels, mapped_sentiment_labels)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Records Classified per Second: {records_classified_per_second:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4f7ce31-4324-46f3-99c3-d6b6b5325e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-cluster centroid distances:\n",
      " [[ 0.          2.33667353  2.40180738  8.56946932  6.94779514  7.28260922]\n",
      " [ 2.33667353  0.          1.14731826  8.92107859  6.72770616  7.26697858]\n",
      " [ 2.40180738  1.14731826  0.          8.84242428  6.63620762  7.23532672]\n",
      " [ 8.56946932  8.92107859  8.84242428  0.         10.72656551 10.56230164]\n",
      " [ 6.94779514  6.72770616  6.63620762 10.72656551  0.          9.80764445]\n",
      " [ 7.28260922  7.26697858  7.23532672 10.56230164  9.80764445  0.        ]]\n",
      "Silhouette Score: 0.2730\n",
      "Davies-Bouldin Index: 1.6681\n",
      "Average Intra-cluster Similarity: 1.1800\n"
     ]
    }
   ],
   "source": [
    "# 1. Calculate Centroid Distances (Euclidean distance between centroids)\n",
    "centroids = kmeans_with_entities.cluster_centers_\n",
    "inter_cluster_distances = np.linalg.norm(centroids[:, np.newaxis] - centroids, axis=2)\n",
    "print(\"Inter-cluster centroid distances:\\n\", inter_cluster_distances)\n",
    "\n",
    "# 2. Calculate Silhouette Score\n",
    "silhouette_avg = silhouette_score(X_combined_with_entities_pca, predicted_labels)\n",
    "print(f\"Silhouette Score: {silhouette_avg:.4f}\")\n",
    "\n",
    "# 3. Calculate Davies-Bouldin Index\n",
    "davies_bouldin = davies_bouldin_score(X_combined_with_entities_pca, predicted_labels)\n",
    "print(f\"Davies-Bouldin Index: {davies_bouldin:.4f}\")\n",
    "\n",
    "# 4. Calculate Average Intra-cluster Similarity (average distance within clusters)\n",
    "# Intra-cluster distance (average distance within each cluster)\n",
    "intra_cluster_similarity = []\n",
    "for cluster_id in range(kmeans_with_entities.n_clusters):\n",
    "    cluster_points = X_combined_with_entities_pca[predicted_labels == cluster_id]\n",
    "    cluster_center = centroids[cluster_id]\n",
    "    intra_cluster_similarity.append(np.mean(np.linalg.norm(cluster_points - cluster_center, axis=1)))\n",
    "\n",
    "average_intra_cluster_similarity = np.mean(intra_cluster_similarity)\n",
    "print(f\"Average Intra-cluster Similarity: {average_intra_cluster_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70b794db-da5a-4f98-a82e-897e1c594487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Accuracy Test Results:\n",
      "Accuracy: 0.3906\n",
      "Precision: 0.7497\n",
      "Recall: 0.3906\n",
      "F1-Score: 0.2865\n"
     ]
    }
   ],
   "source": [
    "#random test\n",
    "random_labels = np.random.choice([1, -1], size=len(data), replace=True)\n",
    "\n",
    "# Step 2: Get the predicted labels from your trained KMeans model\n",
    "predicted_labels = kmeans_with_entities.labels_\n",
    "\n",
    "# Step 3: Evaluate the clustering performance by comparing predicted labels to random labels\n",
    "accuracy = accuracy_score(random_labels, predicted_labels)\n",
    "precision = precision_score(random_labels, predicted_labels, average='weighted', zero_division=1)\n",
    "recall = recall_score(random_labels, predicted_labels, average='weighted', zero_division=1)\n",
    "f1 = f1_score(random_labels, predicted_labels, average='weighted', zero_division=1)\n",
    "\n",
    "# Step 4: Print the evaluation metrics\n",
    "print(f\"Random Accuracy Test Results:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de0447b4-850d-4372-a27c-4d14dfba8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torchfrom transformers \n",
    "import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e02f1609-126e-4ac8-aebb-3876c6b63838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get BERT embeddings for a given text\n",
    "def get_bert_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        # Tokenize and encode the text\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        \n",
    "        # Get the embeddings from BERT (the output of the last hidden layer)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Extract the last hidden state (embeddings)\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        # Get the mean of all token embeddings to get the sentence embedding\n",
    "        sentence_embedding = torch.mean(last_hidden_states, dim=1).squeeze().numpy()\n",
    "        embeddings.append(sentence_embedding)\n",
    "    \n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Example usage to get BERT embeddings for your dataset\n",
    "texts = data['cleaned_body'].tolist()  # Assuming you have a column 'cleaned_body'\n",
    "bert_embeddings = get_bert_embeddings(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "105071ca-47c4-4921-82c9-f54c088aa648",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "bert_embeddings_reduced = pca.fit_transform(bert_embeddings)\n",
    "\n",
    "# Step 5: Apply KMeans clustering using BERT embeddings\n",
    "kmeans_with_bert = KMeans(n_clusters=6, random_state=42)\n",
    "kmeans_with_bert.fit(bert_embeddings_reduced)\n",
    "\n",
    "# Add cluster labels to the dataframe\n",
    "predicted_labels_bert = kmeans_with_bert.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "daa88304-d2d8-4f90-bde3-072721cffe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████| 361/361 [00:00<00:00, 2023.24 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Fine-tune BERT for sentiment analysis\u001b[39;00m\n\u001b[32m      9\u001b[39m model_for_sentiment = BertForSequenceClassification.from_pretrained(\u001b[33m'\u001b[39m\u001b[33mbert-base-uncased\u001b[39m\u001b[33m'\u001b[39m, num_labels=\u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# 2 labels (positive/negative)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./results\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./logs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m trainer = Trainer(\n\u001b[32m     21\u001b[39m     model=model_for_sentiment,\n\u001b[32m     22\u001b[39m     args=training_args,\n\u001b[32m     23\u001b[39m     train_dataset=dataset,\n\u001b[32m     24\u001b[39m     eval_dataset=dataset,  \u001b[38;5;66;03m# Or use a separate validation dataset\u001b[39;00m\n\u001b[32m     25\u001b[39m )\n\u001b[32m     27\u001b[39m trainer.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:132\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, tp_size, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/training_args.py:1761\u001b[39m, in \u001b[36mTrainingArguments.__post_init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[32m   1760\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[32m-> \u001b[39m\u001b[32m1761\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m   1763\u001b[39m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[32m   1764\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.average_tokens_across_devices:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/training_args.py:2297\u001b[39m, in \u001b[36mTrainingArguments.device\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2293\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2294\u001b[39m \u001b[33;03mThe device used by this process.\u001b[39;00m\n\u001b[32m   2295\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2296\u001b[39m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2297\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_devices\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/generic.py:67\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, objtype)\u001b[39m\n\u001b[32m     65\u001b[39m cached = \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     cached = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/training_args.py:2167\u001b[39m, in \u001b[36mTrainingArguments._setup_devices\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[32m   2166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[32m-> \u001b[39m\u001b[32m2167\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m   2168\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2169\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[33m'\u001b[39m\u001b[33maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2170\u001b[39m         )\n\u001b[32m   2171\u001b[39m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[32m   2172\u001b[39m accelerator_state_kwargs = {\u001b[33m\"\u001b[39m\u001b[33menabled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33muse_configured_state\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
      "\u001b[31mImportError\u001b[39m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset for fine-tuning\n",
    "\n",
    "dataset = Dataset.from_pandas(data)  # Assuming your data is in a Pandas DataFrame\n",
    "dataset = dataset.map(lambda x: tokenizer(x['cleaned_body'], truncation=True, padding=True, max_length=512))\n",
    "\n",
    "# Fine-tune BERT for sentiment analysis\n",
    "model_for_sentiment = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)  # 2 labels (positive/negative)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=200,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_for_sentiment,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,  # Or use a separate validation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2eb094aa-d3e3-41e3-80ac-940817c5e496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS backend\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS backend\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01ad6f85-159f-43eb-b27d-0ed917ab8a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d100cbe-7960-4af3-b7e1-ed5ac81151f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2dgs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
